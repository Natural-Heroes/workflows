---
phase: 03-rate-limiting-resilience
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - mcp/mrpeasy/src/services/mrpeasy/rate-limiter.ts
  - mcp/mrpeasy/src/services/mrpeasy/request-queue.ts
  - mcp/mrpeasy/src/services/mrpeasy/retry.ts
  - mcp/mrpeasy/src/services/mrpeasy/circuit-breaker.ts
autonomous: true
---

<objective>
Create resilience utilities for MRPeasy API: rate limiter, request queue, retry logic, and circuit breaker.

Purpose: MRPeasy has strict rate limits (1 concurrent request, 100 per 10 seconds). These utilities protect against rate limit violations and handle transient failures gracefully.
Output: Four standalone utility modules ready for integration into the API client.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/02-api-client-tools/02-01-SUMMARY.md

@mcp/mrpeasy/src/services/mrpeasy/client.ts
@mcp/mrpeasy/src/lib/logger.ts
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create Token Bucket Rate Limiter</name>
  <files>mcp/mrpeasy/src/services/mrpeasy/rate-limiter.ts</files>
  <action>
Create a token bucket rate limiter for MRPeasy's 100 requests per 10 seconds limit:

1. TokenBucket class:
   - Constructor takes: capacity (100), refillRate (10 tokens/second), refillInterval (1000ms)
   - `tryConsume()` method: returns true if token available, false if rate limited
   - `waitForToken()` method: returns Promise that resolves when token available
   - Tokens refill continuously (10 per second to reach 100 in 10s)

2. Implementation pattern:
   ```typescript
   export class TokenBucket {
     private tokens: number;
     private readonly capacity: number;
     private readonly refillRate: number; // tokens per ms
     private lastRefill: number;

     constructor(capacity: number, refillPerSecond: number) {
       this.capacity = capacity;
       this.tokens = capacity;
       this.refillRate = refillPerSecond / 1000;
       this.lastRefill = Date.now();
     }

     private refill(): void {
       const now = Date.now();
       const elapsed = now - this.lastRefill;
       const newTokens = elapsed * this.refillRate;
       this.tokens = Math.min(this.capacity, this.tokens + newTokens);
       this.lastRefill = now;
     }

     tryConsume(): boolean {
       this.refill();
       if (this.tokens >= 1) {
         this.tokens -= 1;
         return true;
       }
       return false;
     }

     async waitForToken(): Promise<void> {
       while (!this.tryConsume()) {
         // Wait for next refill
         await new Promise(r => setTimeout(r, Math.ceil(1 / this.refillRate)));
       }
     }
   }
   ```

3. Export factory function `createRateLimiter()` with MRPeasy defaults (100 capacity, 10 per second).

Use logger for debug logging when rate limiting occurs.
  </action>
  <verify>npx tsc --noEmit passes</verify>
  <done>TokenBucket class with tryConsume() and waitForToken() methods exported</done>
</task>

<task type="auto">
  <name>Task 2: Create Request Queue</name>
  <files>mcp/mrpeasy/src/services/mrpeasy/request-queue.ts</files>
  <action>
Create a request queue that enforces single-concurrent request execution:

1. RequestQueue class:
   - Internal queue of pending request functions
   - `enqueue<T>(fn: () => Promise<T>): Promise<T>` - adds request to queue, returns result
   - Processes one request at a time (max 1 concurrent)
   - FIFO ordering

2. Implementation pattern:
   ```typescript
   export class RequestQueue {
     private queue: Array<{
       fn: () => Promise<unknown>;
       resolve: (value: unknown) => void;
       reject: (error: unknown) => void;
     }> = [];
     private processing = false;

     async enqueue<T>(fn: () => Promise<T>): Promise<T> {
       return new Promise((resolve, reject) => {
         this.queue.push({ fn, resolve: resolve as (v: unknown) => void, reject });
         this.processNext();
       });
     }

     private async processNext(): Promise<void> {
       if (this.processing || this.queue.length === 0) return;

       this.processing = true;
       const { fn, resolve, reject } = this.queue.shift()!;

       try {
         const result = await fn();
         resolve(result);
       } catch (error) {
         reject(error);
       } finally {
         this.processing = false;
         this.processNext();
       }
     }
   }
   ```

3. Export factory function `createRequestQueue()`.

Log queue depth when requests are enqueued (debug level).
  </action>
  <verify>npx tsc --noEmit passes</verify>
  <done>RequestQueue class with enqueue() method that ensures single concurrent execution</done>
</task>

<task type="auto">
  <name>Task 3: Create Retry Logic with Exponential Backoff</name>
  <files>mcp/mrpeasy/src/services/mrpeasy/retry.ts</files>
  <action>
Create retry utility with exponential backoff and jitter:

1. RetryConfig interface:
   ```typescript
   interface RetryConfig {
     maxAttempts: number;      // default 3
     baseDelayMs: number;      // default 1000
     maxDelayMs: number;       // default 30000
     jitterFactor: number;     // default 0.2 (±20%)
     retryableStatuses: number[]; // default [429, 503]
   }
   ```

2. `withRetry<T>(fn: () => Promise<T>, config?: Partial<RetryConfig>): Promise<T>`
   - Executes fn, retries on retryable errors
   - Exponential backoff: delay = baseDelay * 2^attempt
   - Jitter: delay ± (delay * jitterFactor * random)
   - Respects maxDelay cap
   - Throws after maxAttempts exhausted

3. Helper functions:
   - `calculateDelay(attempt: number, config: RetryConfig): number`
   - `isRetryable(error: unknown, config: RetryConfig): boolean` - checks MrpEasyApiError status

4. Implementation pattern:
   ```typescript
   export async function withRetry<T>(
     fn: () => Promise<T>,
     config?: Partial<RetryConfig>
   ): Promise<T> {
     const cfg = { ...DEFAULT_CONFIG, ...config };
     let lastError: unknown;

     for (let attempt = 0; attempt < cfg.maxAttempts; attempt++) {
       try {
         return await fn();
       } catch (error) {
         lastError = error;

         if (!isRetryable(error, cfg) || attempt === cfg.maxAttempts - 1) {
           throw error;
         }

         const delay = calculateDelay(attempt, cfg);
         logger.warn('Retrying request', { attempt: attempt + 1, delay });
         await new Promise(r => setTimeout(r, delay));
       }
     }

     throw lastError;
   }
   ```

Import MrpEasyApiError from client.ts for status checking.
  </action>
  <verify>npx tsc --noEmit passes</verify>
  <done>withRetry() function with exponential backoff, jitter, and retryable status detection</done>
</task>

<task type="auto">
  <name>Task 4: Create Circuit Breaker</name>
  <files>mcp/mrpeasy/src/services/mrpeasy/circuit-breaker.ts</files>
  <action>
Create circuit breaker to protect against sustained failures:

1. CircuitBreaker states: CLOSED, OPEN, HALF_OPEN

2. CircuitBreakerConfig interface:
   ```typescript
   interface CircuitBreakerConfig {
     failureThreshold: number;  // failures to open (default 5)
     successThreshold: number;  // successes to close (default 2)
     timeout: number;           // ms before half-open (default 30000)
   }
   ```

3. CircuitBreaker class:
   ```typescript
   export class CircuitBreaker {
     private state: 'CLOSED' | 'OPEN' | 'HALF_OPEN' = 'CLOSED';
     private failures = 0;
     private successes = 0;
     private lastFailure = 0;

     constructor(private config: CircuitBreakerConfig) {}

     async execute<T>(fn: () => Promise<T>): Promise<T> {
       if (this.state === 'OPEN') {
         if (Date.now() - this.lastFailure >= this.config.timeout) {
           this.state = 'HALF_OPEN';
           this.successes = 0;
         } else {
           throw new CircuitBreakerOpenError('Circuit breaker is open');
         }
       }

       try {
         const result = await fn();
         this.onSuccess();
         return result;
       } catch (error) {
         this.onFailure();
         throw error;
       }
     }

     private onSuccess(): void {
       if (this.state === 'HALF_OPEN') {
         this.successes++;
         if (this.successes >= this.config.successThreshold) {
           this.state = 'CLOSED';
           this.failures = 0;
         }
       } else {
         this.failures = 0;
       }
     }

     private onFailure(): void {
       this.failures++;
       this.lastFailure = Date.now();
       if (this.failures >= this.config.failureThreshold) {
         this.state = 'OPEN';
       }
     }

     getState(): string { return this.state; }
   }
   ```

4. Export CircuitBreakerOpenError class for callers to catch.

5. Export factory function `createCircuitBreaker()` with MRPeasy defaults.

Log state transitions at info level.
  </action>
  <verify>npx tsc --noEmit passes</verify>
  <done>CircuitBreaker class with CLOSED/OPEN/HALF_OPEN states and configurable thresholds</done>
</task>

</tasks>

<verification>
Before declaring plan complete:
- [ ] `npm run typecheck` passes
- [ ] All four modules created in src/services/mrpeasy/
- [ ] TokenBucket has tryConsume() and waitForToken()
- [ ] RequestQueue has enqueue() with single-concurrent guarantee
- [ ] withRetry() has exponential backoff with jitter
- [ ] CircuitBreaker has CLOSED/OPEN/HALF_OPEN states
- [ ] All modules use logger for appropriate logging
</verification>

<success_criteria>
- All tasks completed
- TypeScript compiles without errors
- 4 resilience utility modules ready for integration
- Each module is independently testable
</success_criteria>

<output>
After completion, create `.planning/phases/03-rate-limiting-resilience/03-01-SUMMARY.md`
</output>
